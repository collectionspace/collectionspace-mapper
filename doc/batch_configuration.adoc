ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:toc:
:toc-placement!:

= `collectionspace-mapper` batch configuration options

toc::[]

A JSON config hash may be passed to a new `Mapper::DataHandler` to control various aspects of the data transformation.

.Example config JSON
[source,javascript]
----
{
  "delimiter": ";",
  "subgroup_delimiter": "^^",
  "response_mode": "verbose",
  "strip_id_values": true,
  "multiple_recs_found": "fail",
  "check_record_status" : true,
  "status_check_method" : 'client',
  "search_if_not_cached": true,
  "force_defaults": false,
  "date_format": "month day year",
  "two_digit_year_handling": "convert to four digit",
  "transforms": {
    "collection": {
      "special": [
        "downcase_value"
      ],
      "replacements": [{
        "find": " ",
        "replace": "-",
        "type": "plain"
      }]
    }
  },
  "default_values": {
    "publishTo": "DPLA;Omeka",
    "collection": "library-collection"
  }
}
----

== batch_mode

`full record`:: The "normal" mode, using CSV template that has all fields for the record type. Allows you to create a full record from each row of data in the CSV. For structured dates, a date string is entered in the column for the structured date group field, and teh application handles parsing the date details. This processing cannot set period, association, note, certainty, qualifier, value, or unit fields within structured date detailed fields.
`date details`:: Allows you to skip the application's normal parsing/processing of date strings into structured dates, and directly ingest all structured date detailed fields.

== check_record_status

If `true`, looks up each record via cspace-services API and sets `Response.record_status` to `:exists` if the record is found, or `:new` if it is not.

If `false`, does not search services API for the record. Sets `Response.record_status` to `:new`.

[NOTE]
====
Set this to false only if you are certain no records in your data exist in CollectionSpace. Otherwise, `cspace-batch-import` record transfer processes will fail for records that already exist.
====

- *Required?:* yes
- *Defaults to:* true
- *Data type*: boolean
- *Allowed values*: `true`, `false`

== date_format

Only has an effect on dates like: 3/4/2020 or 03-04-2020.

If `month day year`, these dates would be interpreted as March 4, 2020.

If `day month year`, these dates would be interpreted as April 3, 2020.

- *Required?:* yes
- *Defaults to:* `month day year`
- *Data type*: string
- *Allowed values*: `month day year`, `day month year`

== default_values

Typically, it is preferred that you set default values in your prepared source data. However, you can also specify default values to be applied to all fields via this config option.

* *Required?:* no
* *Defaults to:* empty/nothing
* *Data type*: Hash
* *Allowed values*:
** Hash key: String data type. The CSV column name (i.e. data hash field) to which specified transform(s) should be applied
** Hash value: String data type. The default value

See also <<force_defaults>>.

== delimiter

Delimiter character or string used to split repeatable values within the cell of a CSV.

- *Required?:* yes
- *Defaults to:* |
- *Data type*: string

See also <<subgroup_delimiter>>.

== force_defaults

Only has an effect if you are also providing <<default_values>> in your config.

Relevant if some fields for which you are providing `default_values` have other values in the source data (CSV).

If `false`, default values will not replace or be added to values passed in via the data hash; default value will be inserted if field is missing or empty in data hash.

If `true`, default value will replace any data hash values.

- *Required?:* yes
- *Defaults to:* false
- *Data type*: boolean
- *Allowed values*: `true`, `false`

== multiple_recs_found

Controls what happens when the mapper looks up the status (new vs. existing) of the record being mapped in your CollectionSpace instance, and more than one record with the same ID is found.

If `fail`, the mapper returns an error for that record. You will not be able to transfer that record with the batch importer.

`fail` is the default because it is generally unsafe to update or delete a record when it's not clear which record should be updated.

WARNING: Do not use this option at all if you are not 100% certain of what it does. It has the potential to be very destructive to your data.

There may be odd cases where you end up with true duplicate records, in your system, however. The `use_first` value for this config option was added to enable batch deletion of known duplicate records. If your records with the same ID are not actually duplicates, this can be very destructive, so *use with care*.

If using this option to enable batch deletes of records with duplicate ids, you have no control over which record with the given id will be deleted. If they are true duplicate records, that is fine. Note that, only one record with a given ID is ever updated or deleted at a time via the CSV importer. If you had 3 records with the same id, and you used this option to do a delete transfer, you will still have 2 records with the same id in the system.

While it is possible to use this setting to batch update existing records that do not have unique ids, it is strongly discouraged. You will not have any control over _which_ of the records with a non-unique id is updated. If the records sharing an ID were not duplicate records, you may be updating the wrong record. If they were duplicates, they won't be after you update one, but you will still have duplicate ids in the system.

- *Required?:* no
- *Defaults to:* fail
- *Data type*: string
- *Allowed values*: `fail`, `use_first`

== null_value_string_handling

Controls how fields containing `%NULLVALUE%` are handled.

- *Required?:* no
- *Defaults to:* `delete`
- *Data type*: string
- *Allowed values*: `delete`, `empty`

== response_mode

If `normal`, `Mapper::Response.orig_data` returns the original data hash, and `Mapper::Response.doc` returns the resulting XML document.

If `verbose`, `Mapper::Response` also has the following attributes, which may be helpful in debugging:

- `.merged_data` - result of merging any default values into `orig_data`.
- `.split_data` - result of splitting `merged_data` using `delimiter` and `subgroup_delimiter`. All field values are now arrays.
- `.transformed_data` - result of any transformations applied to `split_data`.
- `.combined_data` - result of combining separate data columns (such as `approvedByPerson` and `approvedByOrganization`) into one CollectionSpace field (`approvedBy`).

- *Required?:* yes
- *Defaults to:* normal
- *Data type*: string
- *Allowed values*: `normal`, `verbose`

== search_if_not_cached

Controls whether an search is done via the Services API (via collectionspace-client) to retrieve the refname or csid of terms or records for which no cache entry exists.

WARNING: Only set this to `false` if you have cached all existing data values prior to mapping, and the cache lifetime is long enough that values will remained cached throughout the mapping process

IMPORTANT: If using the CollectionSpace CSV Importer, leave this `true`. Because it assumes it is being used on live production data which may be changing, that tool does not cache all values in your instance before mapping, and the cache lifetime is quite short.

- *Required?:* yes
- *Defaults to:* true
- *Data type*: boolean
- *Allowed values*: `true`, `false`

== status_check_method

Controls whether the status of each record is determined via querying the services API, or by querying a cache.

[WARNING]
====
**Do not** set this to `cache` unless:

* you know you have an up-to-date `CollectionSpace::RefCache` accurately populated with all CSIDs from the CollectionSpace instance you are working with
* you know no one is adding or deleting any records from the CollectionSpace instance you are working with while you are preparing records to be transferred into it

If you use this in other circumstances, it is possible to inadvertently add duplicate records.
====

- *Required?:* yes
- *Defaults to:* `client`
- *Data type*: boolean
- *Allowed values*: `client`, `cache`

== strip_id_values

Controls whether or not leading and trailing spaces are removed from values in record identifier fields before processing.

The use case for this is when you need to update records that have been created in the UI with a space at the beginning or end of the record identifier field value.

If the mapper strips the spaces off, then the record will not match the existing record and the CSV Importer will only be able to create the record as a new record.

If you get existing records that unexpectedly cannot be transfered as updates, check whether they are being flagged as new records because spaces are messing up the matching. If this is the case, setting this to `false` may allow you to to update those records.

- *Required?:* no
- *Defaults to:* true
- *Data type*: boolean
- *Allowed values*: `true`, `false`

== subgroup_delimiter

Delimiter character or string used to split repeatable values nested inside other repeatable values (example: titleTranslation, titleTranslationLanguage).

This is only used when if you are importing data into a repeatable field group within a larger repeatable field group.

- *Required?:* yes
- *Defaults to:* ^^
- *Data type*: string

See also <<delimiter>>.

== transforms

While it is typically preferred to prepare your source data as required prior to mapping, this lets you specify some simple data transformations that can be applied as part of the mapping process.

* *Required?:* no
* *Defaults to:* empty/nothing
* *Data type*: Hash
* *Allowed values*:
** Hash key: String data type. The CSV column name (i.e. data hash field) to which specified transform(s) should be applied
** Hash value: Hash data type. Structured transformation instructions to be applied.

== two_digit_year_handling

Only has an effect on dates like: 1-21-19 or 1-21-45, where a four digit year is not provided.

Entering such dates in CollectionSpace manually would result in the years being parsed as 0019 and 0045.

Setting this to `literal` will keep that behavior.

Setting this to `coerce` results in the years being parsed as 2019 and 1945 via the following algorithm:

- get the current year
- if the two-digit year in the data is less than or equal to the last two digits of the current year, use the first two digits of the current year as the first two digits of the coerced four-digit year.
- if the two-digit year in the data is greater than the last two digits of the current year, use the first two digits of the current year *minus one* as the first two digits of the coerced four-digit year.

- *Required?:* yes
- *Defaults to:* `coerce`
- *Data type*: string
- *Allowed values*: `coerce`, `literal`
